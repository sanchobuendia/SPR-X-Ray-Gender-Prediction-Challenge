{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQe_NTuSCABB"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "    print(\"Device:\", tpu.master())\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR6VZEEqCPNZ"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIdhmXhdDFtD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erkLkucpCPPk"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\"/content/gdrive/MyDrive/xray\",\n",
        "                                                      validation_split=0.2,\n",
        "                                                      subset=\"training\",   \n",
        "                                                      seed=123,\n",
        "                                                      image_size=(img_height, img_width),\n",
        "                                                      batch_size=batch_size\n",
        "                                                        )\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\"/content/gdrive/MyDrive/xray\",\n",
        "                                                      validation_split=0.2,\n",
        "                                                      subset=\"validation\",     \n",
        "                                                      seed=123,\n",
        "                                                      image_size=(img_height, img_width),\n",
        "                                                      batch_size=batch_size\n",
        "                                                        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKAaXno7CPao"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "test_ds = val_ds.take(10) \n",
        "val_ds = val_ds.skip(10)\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac7g5r0ICPeK"
      },
      "outputs": [],
      "source": [
        "# Gender Classification on TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOI-k0PxChp1"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = [180, 180]\n",
        "#CLASS_NAMES = [\"NORMAL\", \"PNEUMONIA\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwYUJSQEChsF"
      },
      "outputs": [],
      "source": [
        "## Build the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ0tfsyVChuZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def conv_block(filters, inputs):\n",
        "    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
        "    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    outputs = layers.MaxPool2D()(x)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def dense_block(units, dropout_rate, inputs):\n",
        "    x = layers.Dense(units, activation=\"relu\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    outputs = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynquay7UChwe"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
        "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "\n",
        "    x = conv_block(32, x)\n",
        "    x = conv_block(64, x)\n",
        "\n",
        "    x = conv_block(128, x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = conv_block(256, x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = dense_block(512, 0.7, x)\n",
        "    x = dense_block(128, 0.5, x)\n",
        "    x = dense_block(64, 0.3, x)\n",
        "\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUtZBY3NChyy"
      },
      "outputs": [],
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCLb92wNCh08"
      },
      "outputs": [],
      "source": [
        "### Defining callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y977PfGVCh3P"
      },
      "outputs": [],
      "source": [
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"xray_model.h5\", save_best_only=True)\n",
        "\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N5zZswBCh61"
      },
      "outputs": [],
      "source": [
        "initial_learning_rate = 0.015\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqZELY63CGvI"
      },
      "outputs": [],
      "source": [
        "### Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwDoNXC0C21z"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    model = build_model()\n",
        "\n",
        "    METRICS = [\n",
        "        tf.keras.metrics.BinaryAccuracy(),\n",
        "        tf.keras.metrics.Precision(name=\"precision\"),\n",
        "        tf.keras.metrics.Recall(name=\"recall\"),\n",
        "    ]\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=METRICS,\n",
        "    )\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=100,\n",
        "    validation_data=val_ds,\n",
        "    #class_weight=class_weight,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXi5dC4wC238"
      },
      "outputs": [],
      "source": [
        "## Visualizing model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8dhDqIFC26T"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate([\"precision\", \"recall\", \"binary_accuracy\", \"loss\"]):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].set_title(\"Model {}\".format(met))\n",
        "    ax[i].set_xlabel(\"epochs\")\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend([\"train\", \"val\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K5ykcQeC28j"
      },
      "outputs": [],
      "source": [
        "### Predict and evaluate results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdkbGWDbC2-8"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_ds, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in test_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "metadata": {
        "id": "7BstWSZkVt5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imageId - same as the PNG filename\n",
        "# gender - 0 for female and 1 for male\n",
        "CLASS_NAMES = [\"FEMALE\", \"MALE\"]"
      ],
      "metadata": {
        "id": "DUHPD2L-WCeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyGMVDy9C3Ax"
      },
      "outputs": [],
      "source": [
        "for image, label in test_ds.take(1):\n",
        "  for j in range(0,30):\n",
        "    prediction = model.predict(test_ds.take(1))[j]\n",
        "    scores = [1 - prediction, prediction]\n",
        "    for score, name in zip(scores, CLASS_NAMES):\n",
        "        print(\"This image is %.2f percent %s\" % ((100 * score), name))\n",
        "    plt.imshow(image[j] / 255.0)\n",
        "    plt.title(CLASS_NAMES[label[j].numpy()])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roXBSlQiC3Ea"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}