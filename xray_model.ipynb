{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQe_NTuSCABB"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#try:\n",
        "#    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "#    print(\"Device:\", tpu.master())\n",
        "#    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "#except:\n",
        "#    strategy = tf.distribute.get_strategy()\n",
        "#print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.test.gpu_device_name()\n",
        "if len(strategy) > 0:\n",
        "    print(\"Found GPU at: {}\".format(strategy))\n",
        "else:\n",
        "    strategy = \"/device:CPU:0\"\n",
        "    print(\"No GPU, using {}.\".format(strategy))"
      ],
      "metadata": {
        "id": "_sCriHvfiGOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "OsFruE04KfBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR6VZEEqCPNZ"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIdhmXhdDFtD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erkLkucpCPPk"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\"/content/gdrive/MyDrive/xray\",\n",
        "                                                      validation_split=0.2,\n",
        "                                                      subset=\"training\",   \n",
        "                                                      seed=123,\n",
        "                                                      image_size=(img_height, img_width),\n",
        "                                                      batch_size=batch_size\n",
        "                                                        )\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\"/content/gdrive/MyDrive/xray\",\n",
        "                                                      validation_split=0.2,\n",
        "                                                      subset=\"validation\",     \n",
        "                                                      seed=123,\n",
        "                                                      image_size=(img_height, img_width),\n",
        "                                                      batch_size=batch_size\n",
        "                                                        )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gRvOT9l3X4YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKAaXno7CPao"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "test_ds = val_ds.take(10) \n",
        "val_ds = val_ds.skip(10)\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac7g5r0ICPeK"
      },
      "outputs": [],
      "source": [
        "# Gender Classification on TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOI-k0PxChp1"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = [180, 180]\n",
        "#CLASS_NAMES = [\"NORMAL\", \"PNEUMONIA\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwYUJSQEChsF"
      },
      "outputs": [],
      "source": [
        "## Build the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ0tfsyVChuZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def conv_block(filters, inputs):\n",
        "    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
        "    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    outputs = layers.MaxPool2D()(x)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def dense_block(units, dropout_rate, inputs):\n",
        "    x = layers.Dense(units, activation=\"relu\")(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    outputs = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynquay7UChwe"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
        "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "\n",
        "    x = conv_block(32, x)\n",
        "    x = conv_block(64, x)\n",
        "\n",
        "    x = conv_block(128, x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = conv_block(256, x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = dense_block(512, 0.7, x)\n",
        "    x = dense_block(128, 0.5, x)\n",
        "    x = dense_block(64, 0.3, x)\n",
        "\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUtZBY3NChyy"
      },
      "outputs": [],
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCLb92wNCh08"
      },
      "outputs": [],
      "source": [
        "### Defining callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y977PfGVCh3P"
      },
      "outputs": [],
      "source": [
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"xray_model.h5\", save_best_only=True)\n",
        "\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N5zZswBCh61"
      },
      "outputs": [],
      "source": [
        "initial_learning_rate = 0.015\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqZELY63CGvI"
      },
      "outputs": [],
      "source": [
        "### Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwDoNXC0C21z"
      },
      "outputs": [],
      "source": [
        "with tf.device(strategy):\n",
        "    model = build_model()\n",
        "\n",
        "    METRICS = [\n",
        "        tf.keras.metrics.BinaryAccuracy(),\n",
        "        tf.keras.metrics.Precision(name=\"precision\"),\n",
        "        tf.keras.metrics.Recall(name=\"recall\"),\n",
        "    ]\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=METRICS,\n",
        "    )\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=100,\n",
        "    validation_data=val_ds,\n",
        "    #class_weight=class_weight,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXi5dC4wC238"
      },
      "outputs": [],
      "source": [
        "## Visualizing model performance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "muDkybZBZT26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8dhDqIFC26T"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, met in enumerate([\"precision\", \"recall\", \"binary_accuracy\", \"loss\"]):\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].plot(history.history[met])\n",
        "    ax[i].set_title(\"Model {}\".format(met))\n",
        "    ax[i].set_xlabel(\"epochs\")\n",
        "    ax[i].set_ylabel(met)\n",
        "    ax[i].legend([\"train\", \"val\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K5ykcQeC28j"
      },
      "outputs": [],
      "source": [
        "### Predict and evaluate results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdkbGWDbC2-8"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_ds, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for image, label in test_ds.take(1):\n",
        "#  print(\"Image shape: \", image.numpy().shape)\n",
        "#  print(\"Label: \", label.numpy())"
      ],
      "metadata": {
        "id": "7BstWSZkVt5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imageId - same as the PNG filename\n",
        "# gender - 0 for female and 1 for male\n",
        "CLASS_NAMES = [\"FEMALE\", \"MALE\"]"
      ],
      "metadata": {
        "id": "DUHPD2L-WCeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/gdrive/MyDrive/xraytest\", \n",
        "    batch_size=32, \n",
        "    image_size=(img_height, img_width), shuffle=False\n",
        ")\n",
        "file_paths = test.file_paths\n",
        "test = test.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "szyA4-362BhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict = {'imageId': file_paths}\n",
        "df = pd.DataFrame(dict)\n",
        "df['imageId'] = df.imageId.str.split('/').str[6]\n",
        "df['imageId'] = df.imageId.str.split('.').str[0]\n",
        "df['imageId'] = df['imageId'].astype(int)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "XKLpn08_3TiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(test, batch_size=batch_size)\n",
        "preds = preds.round(2)\n",
        "preds = np.squeeze(preds)"
      ],
      "metadata": {
        "id": "cTZaCmKZey4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['gender'] = preds"
      ],
      "metadata": {
        "id": "BSZXW-Y4_Rfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_classes(pred_probs, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Takes in a list of predicted probabilities and returns a list of class labels.\n",
        "    The class labels are determined by comparing each probability to a threshold value.\n",
        "    If the probability is greater than or equal to the threshold, the label is 1. Otherwise, it is 0.\n",
        "    Args:\n",
        "        pred_probs (list): A list of predicted probabilities.\n",
        "        threshold (float): The probability threshold for determining the class label. Default is 0.5.\n",
        "    Returns:\n",
        "        A list of class labels (0 or 1) corresponding to each predicted probability.\n",
        "    \"\"\"\n",
        "    class_labels = []\n",
        "    for prob in pred_probs:\n",
        "        if prob >= threshold:\n",
        "            class_labels.append(1)\n",
        "        else:\n",
        "            class_labels.append(0)\n",
        "    return class_labels\n",
        "\n",
        "df['gender'] = label_classes(df['gender'], threshold=0.5)"
      ],
      "metadata": {
        "id": "VtEZzTjnBJAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/gdrive/MyDrive/submission_gender.csv')"
      ],
      "metadata": {
        "id": "AEN37B4NAori"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "D0yKdmhLZsb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyGMVDy9C3Ax"
      },
      "outputs": [],
      "source": [
        "for image, label in test.take(1):\n",
        "  for j in range(0,30):\n",
        "    prediction = model.predict(test_ds.take(1))[j]\n",
        "    scores = [1 - prediction, prediction]\n",
        "    for score, name in zip(scores, CLASS_NAMES):\n",
        "        print(\"This image is %.2f percent %s\" % ((100 * score), name))\n",
        "    plt.imshow(image[j] / 255.0)\n",
        "    plt.title(CLASS_NAMES[label[j].numpy()])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roXBSlQiC3Ea"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}